{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Overview\n",
            "\n",
            "This notebook prepares landings records from the Government of Greenland, Fisheries Department, Fisheries License Control Authority, for the purposes of reproducing the results of the sea ice fishing study.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Load Packages\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This portion of the notebook loads in all of the packages required to run the subsequent code cells. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/Users/huntersnyder/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
                  "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
               ]
            }
         ],
         "source": [
            "import datetime as dt\n",
            "import matplotlib.pyplot as plt\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import seaborn as sns\n",
            "from sklearn.covariance import EllipticEnvelope\n",
            "from tqdm.notebook import tqdm\n",
            "import json\n",
            "from pathlib import Path"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Load and Clean Landings Records\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The landings records that are used in the study are originally recorded by hand in the various landing sites, most commonly fish factories. These records are subject to input error, and formatting error. The following actions identify and resolve errors that prevent accurate interpretation of fishing activities."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "landings = pd.read_csv(\n",
            "    \"../data/raw/landings_raw.csv\",\n",
            "    index_col=0,\n",
            "    encoding=\"ISO-8859-1\",\n",
            "    low_memory=False,\n",
            "    na_values=[\"I/O\"],\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Create New Variable for the Vessel Type\n",
            "To evaluate changes in fishing activity on both the water and the ice, we classify the current vessel types into either water or ice vessels. We also change the vessel type variable, which normally contains the individual vessel types, to be either a water or ice vessel. We create a new variable called vessel, which contains the specific type of vessel."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "vessels = {\n",
            "    \"UJOLLE\": None,\n",
            "    \"USLAEDE\": None,\n",
            "    \"Dinghy\": \"water\",\n",
            "    \"Larger Inshore Vessel\": \"water\",\n",
            "    \"Sled\": \"ice\",\n",
            "    \"Snowmobile\": \"ice\",\n",
            "    \"ATV\": None,\n",
            "}\n",
            "landings[\"vessel\"] = landings.vessel_type\n",
            "landings[\"vessel_type\"] = landings.vessel.map(vessels)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Correct Erroneous Localities Values\n",
            "Some of the localities include districts, which complicate interpretation of results. We group some districts into their parent locality."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "wrong_localities = {\n",
            "    \"Aappilattoq Nanortalimmi\": \"Nanortalik\",\n",
            "    \"Aappilattoq Upernavimmi\": \"Upernavik\",\n",
            "    \"Kuummiit\": \"Kuummiut\",\n",
            "    \"Nuussuaq, Nuuk\": \"Nuuk\",\n",
            "    \"Nuussuaq, Upernavik\": \"Upernavik\",\n",
            "    \"Tasiusaq Nanortalimmi\": \"Nanortalik\",\n",
            "    \"Tasiusaq, Nanortalimmi\": \"Nanortalik\",\n",
            "    \"Tasiusaq, Upernavik\": \"Upernavik\",\n",
            "    \"Tiileqilaaq\": \"Tiniteqilaaq\",\n",
            "}\n",
            "\n",
            "landings.sellers_locality = landings.sellers_locality.replace(\n",
            "    to_replace=wrong_localities\n",
            ")\n",
            "landings.buyers_locality = landings.buyers_locality.replace(to_replace=wrong_localities)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Correct Gears\n",
            "\n",
            "Some of the gears described are classified separarely from each other but are the same. We group these together. We also ensure that the number of tools (aka gears) used is greater than 0."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "wrong_gears = {\n",
            "    \"Set gillnets\": \"Gill nets\",\n",
            "    \"Gill nets\": \"Gill nets\",\n",
            "    \"Longlines (not specified)\": \"Longlines\",\n",
            "}\n",
            "\n",
            "landings[\"gears\"] = landings.gear_en.replace(to_replace=wrong_gears)\n",
            "landings = landings[landings[\"num_tools\"] > 0]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Drop Erroneous Records\n",
            "\n",
            "Landing records without the landing date, the seller id, the position of the harvest, or the locality of the seller, are not able to be evaluated. We drop these records. We also drop records where the fishing time indicated is less than zero. Fishing time is used to calculate efficiency of fishing, in the form of catch per unit of effort. When fishing time is missing, catch per unit of effort cannot be calculated.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Some missing data are okay, but some are an immediate disqualifier for further analysis of that row\n",
            "landings = landings.dropna(\n",
            "    subset=[\"landing_date\", \"seller_id\", \"field_code\", \"sellers_locality\"]\n",
            ")\n",
            "landings = landings[landings[\"fishing_time\"] > 0]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Clean Up Field Codes\n",
            "\n",
            "Field codes are used to grid cell Greenland's fishing areas. These data come from Greenland Fisheries License Control Authority. The spatial information for each landing in the landing records are dropped and the spatial information for each field code is merged onto the landing records. These information are more accurate and less error-prone."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "field_codes = pd.read_csv(\"../resources/fieldcodes.csv\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "landings[\"field_code\"] = landings.field_code.str.replace(\"-\", \"\")\n",
            "\n",
            "\n",
            "def insert_zero_padding(field_code):\n",
            "    try:\n",
            "        return field_code[:2] + f\"{int(field_code[2:]):03d}\"\n",
            "    except (ValueError, TypeError):\n",
            "        return field_code\n",
            "\n",
            "\n",
            "landings[\"field_code\"] = landings.field_code.apply(insert_zero_padding)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "landings = landings.drop(columns=[\"latitude\", \"longitude\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "landings = landings.merge(right=field_codes)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Load Locality Information\n",
            "\n",
            "Information about the localities is limited in the landing records. We bring in additional information, including the type of locality and the municipality it is a part of."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>TEKST_GL</th>\n",
                     "      <th>KOMMUNE</th>\n",
                     "      <th>TYPE</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>Nerlerit Inaat</td>\n",
                     "      <td>Sermersooq</td>\n",
                     "      <td>Bygd</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>Sirius</td>\n",
                     "      <td>UFK</td>\n",
                     "      <td>Station</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>Akunnaaq</td>\n",
                     "      <td>Qaasuitsup</td>\n",
                     "      <td>Bygd</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>Kitsissuarsuit</td>\n",
                     "      <td>Qaasuitsup</td>\n",
                     "      <td>Bygd</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>5</th>\n",
                     "      <td>Ikkatteq</td>\n",
                     "      <td>Sermersooq</td>\n",
                     "      <td>Bygd</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>91</th>\n",
                     "      <td>Daneborg</td>\n",
                     "      <td>UFK</td>\n",
                     "      <td>Station</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>93</th>\n",
                     "      <td>Ikamiut</td>\n",
                     "      <td>Qaasuitsup</td>\n",
                     "      <td>Bygd</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>94</th>\n",
                     "      <td>Nutaarmiut</td>\n",
                     "      <td>Qaasuitsup</td>\n",
                     "      <td>Bygd</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>95</th>\n",
                     "      <td>Ikerasaarsuk, Upernavik</td>\n",
                     "      <td>Qaasuitsup</td>\n",
                     "      <td>Bygd</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>96</th>\n",
                     "      <td>Ungusivik</td>\n",
                     "      <td>Qeqqata</td>\n",
                     "      <td>Bygd</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>92 rows Ã— 3 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "                   TEKST_GL     KOMMUNE     TYPE\n",
                     "0            Nerlerit Inaat  Sermersooq     Bygd\n",
                     "2                    Sirius         UFK  Station\n",
                     "3                  Akunnaaq  Qaasuitsup     Bygd\n",
                     "4            Kitsissuarsuit  Qaasuitsup     Bygd\n",
                     "5                  Ikkatteq  Sermersooq     Bygd\n",
                     "..                      ...         ...      ...\n",
                     "91                 Daneborg         UFK  Station\n",
                     "93                  Ikamiut  Qaasuitsup     Bygd\n",
                     "94               Nutaarmiut  Qaasuitsup     Bygd\n",
                     "95  Ikerasaarsuk, Upernavik  Qaasuitsup     Bygd\n",
                     "96                Ungusivik     Qeqqata     Bygd\n",
                     "\n",
                     "[92 rows x 3 columns]"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "locality_info = pd.read_csv(\"../resources/localities.csv\")\n",
            "locality_info = locality_info[[\"TEKST_GL\", \"KOMMUNE\", \"TYPE\"]]\n",
            "locality_info = locality_info.dropna()\n",
            "locality_info"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "landings = (\n",
            "    landings.merge(locality_info, left_on=\"sellers_locality\", right_on=\"TEKST_GL\")\n",
            "    .rename(\n",
            "        columns={\"KOMMUNE\": \"sellers_municipality\", \"TYPE\": \"sellers_settlement_size\"}\n",
            "    )\n",
            "    .drop(columns=\"TEKST_GL\")\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Create Derived Variables\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Create Seasonal Year\n",
            "\n",
            "To evaluate fishing from Jan-Dec of each year is not helpful because ice fishing seasons occur at the end and the beginning of the year. We know that no ice fishing occurs in August, 8, so we create a seasonal year that spans from August to August of each year. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [],
         "source": [
            "season_start_month = 8\n",
            "\n",
            "landings[\"landing_date\"] = pd.to_datetime(landings.landing_date)\n",
            "landings[\"seasonal_year\"] = landings.landing_date.apply(\n",
            "    lambda x: x.year - 1 if x.month < season_start_month else x.year\n",
            ")\n",
            "landings = landings.query(\"seasonal_year >= 2012 & seasonal_year <= 2022\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Calculate Catch Per Unit of Effort (CPUE)\n",
            "\n",
            "Catch per unit of effort is the quotient of the landed weight of the catch and the time invested, weighted by the number of tools or gears used."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [],
         "source": [
            "landings[\"effective_num_tools\"] = landings[\"num_tools\"]\n",
            "landings.loc[landings.gears == \"Longlines\", \"effective_num_tools\"] /= 100\n",
            "landings[\"cpue\"] = (\n",
            "    landings.amount_in_kg / landings.effective_num_tools / landings.fishing_time\n",
            ")\n",
            "landings = landings.drop(columns=\"effective_num_tools\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Calculate Price Per Kilo (DKK/kg)\n",
            "\n",
            "Kilo price paid to fishers (aka sellers) is the quotient of the sale price (dkk) and the amount of catch landed (kg)."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "landings[\"ppk\"] = landings.value / landings.amount_in_kg\n",
            "landings = landings.replace([np.inf, -np.inf], np.nan)\n",
            "landings = landings.dropna(subset=[\"cpue\", \"ppk\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Outlier Removal\n",
            "\n",
            "Outliers create intepretation issues and are almost always because of human input error on one of the variables, such as the amount of fish landed, the sale price, fishing time. We drop all outliers of kilo price, catch per unit of effort, and the sale price (aka value.)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            "def is_outlier(s):\n",
            "    if s.shape[0] < 3:  # For less than 3 data points, outliers cannot be detected\n",
            "        return s != s\n",
            "    return pd.Series(\n",
            "        EllipticEnvelope(support_fraction=0.8).fit_predict(s.values.reshape(-1, 1))\n",
            "        == -1,\n",
            "        index=s.index,\n",
            "    )\n",
            "\n",
            "\n",
            "landings = landings[\n",
            "    ~landings.groupby(\"sellers_municipality\", group_keys=False)[\"cpue\"].apply(\n",
            "        is_outlier\n",
            "    )\n",
            "]\n",
            "landings = landings[\n",
            "    ~landings.groupby(\"sellers_municipality\", group_keys=False)[\"ppk\"].apply(is_outlier)\n",
            "]\n",
            "landings = landings[\n",
            "    ~landings.groupby(\"sellers_municipality\", group_keys=False)[\"value\"].apply(\n",
            "        is_outlier\n",
            "    )\n",
            "]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Create Derived Dataframes\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Calculate Price Per Kilo According to Locality"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "landings.groupby(by=[\"sellers_locality\", \"seasonal_year\"]).ppk.mean().to_csv(\n",
            "    \"../data/derived/ppk_locality.csv\"\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Ice Landings and Water Landings\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [],
         "source": [
            "ice_landings = landings.query('vessel_type == \"ice\"')\n",
            "water_landings = landings.query('vessel_type == \"water\"')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Total Daily Catch\n",
            "\n",
            "The total daily catch refers to how much ice fishing catch was landed each day, across all of the localities, by year. This dataframe permits interpretation of the development of each fishing season in terms of catch and timing of catch."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [],
         "source": [
            "total_daily_catch = (\n",
            "    ice_landings.groupby(by=[\"seasonal_year\", \"landing_date\"])\n",
            "    .amount_in_kg.sum()\n",
            "    .reset_index()\n",
            ")\n",
            "\n",
            "\n",
            "def calc_seasonal_days(row):\n",
            "    return (row[\"landing_date\"] - dt.datetime(row[\"seasonal_year\"], 8, 1)).days\n",
            "\n",
            "\n",
            "total_daily_catch[\"seasonal_day\"] = total_daily_catch[\n",
            "    [\"landing_date\", \"seasonal_year\"]\n",
            "].apply(calc_seasonal_days, axis=\"columns\")\n",
            "\n",
            "total_daily_catch[\"cumulative\"] = (\n",
            "    total_daily_catch.sort_values(by=\"seasonal_day\")\n",
            "    .groupby(by=[\"seasonal_year\"])\n",
            "    .amount_in_kg.cumsum()\n",
            ")\n",
            "\n",
            "total_daily_catch.to_csv(\"../data/total_daily_catch.csv\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Local Daily Catch\n",
            "\n",
            "Local daily catch refers to how much ice fishing catch was landed in each seasonal year, in each fieldcode, on each day, in each seller's locality. This dataframe permits interpretation of the distribution of catch amounts across a locality's fishing grounds."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [],
         "source": [
            "local_daily_catch = (\n",
            "    landings.query('vessel_type == \"ice\"')\n",
            "    .groupby(by=[\"seasonal_year\", \"field_code\", \"landing_date\", \"sellers_locality\"])\n",
            "    .amount_in_kg.sum()\n",
            "    .reset_index()\n",
            ")\n",
            "\n",
            "\n",
            "def calc_seasonal_days(row):\n",
            "    return (row[\"landing_date\"] - dt.datetime(row[\"seasonal_year\"], 8, 1)).days\n",
            "\n",
            "\n",
            "local_daily_catch[\"seasonal_day\"] = local_daily_catch[\n",
            "    [\"landing_date\", \"seasonal_year\"]\n",
            "].apply(calc_seasonal_days, axis=\"columns\")\n",
            "\n",
            "local_daily_catch[\"cumulative\"] = (\n",
            "    local_daily_catch.sort_values(by=\"seasonal_day\")\n",
            "    .groupby(by=[\"seasonal_year\", \"field_code\", \"sellers_locality\"])\n",
            "    .amount_in_kg.cumsum()\n",
            ")\n",
            "\n",
            "\n",
            "local_daily_catch.to_csv(\"../data/local_daily_catch.csv\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Local First Catch\n",
            "\n",
            "Local first catch is a dataframe listing the very first ice fishing landing, no matter how big or small, in each locality, in each field code, in each seasonal year."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [],
         "source": [
            "local_first_catch = (\n",
            "    local_daily_catch.groupby(by=[\"seasonal_year\", \"field_code\", \"sellers_locality\"])\n",
            "    .seasonal_day.min()\n",
            "    .reset_index()\n",
            "    .rename(columns={\"seasonal_day\": \"first_catch_day\", \"seasonal_year\": \"season\"})\n",
            ")\n",
            "\n",
            "local_first_catch.to_csv(\"../data/local_first_catch.csv\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Local Last Catch\n",
            "\n",
            "Local last catch is a dataframe listing the very last ice fishing landing, no matter how big or small, in each locality, in each field code, in each seasonal year."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [],
         "source": [
            "local_last_catch = (\n",
            "    local_daily_catch.groupby(by=[\"seasonal_year\", \"field_code\", \"sellers_locality\"])\n",
            "    .seasonal_day.max()\n",
            "    .reset_index()\n",
            "    .rename(columns={\"seasonal_day\": \"last_catch_day\", \"seasonal_year\": \"season\"})\n",
            ")\n",
            "local_last_catch.to_csv(\"../data/local_last_catch.csv\")\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Season Length (First/Last Catch Criteria)\n",
            "\n",
            "This calculates the length of the season according to the values calculated in the code cells immediately above."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [],
         "source": [
            "total_first_catch = (\n",
            "    total_daily_catch.groupby(by=[\"seasonal_year\"])\n",
            "    .seasonal_day.min()\n",
            "    .reset_index()\n",
            "    .rename(columns={\"seasonal_day\": \"first_catch_day\", \"seasonal_year\": \"season\"})\n",
            ")\n",
            "\n",
            "total_last_catch = (\n",
            "    total_daily_catch.groupby(by=[\"seasonal_year\"])\n",
            "    .seasonal_day.max()\n",
            "    .reset_index()\n",
            "    .rename(columns={\"seasonal_day\": \"last_catch_day\", \"seasonal_year\": \"season\"})\n",
            ")\n",
            "\n",
            "total_ice_season_length = (\n",
            "    total_last_catch.set_index(\"season\").last_catch_day\n",
            "    - total_first_catch.set_index(\"season\").first_catch_day\n",
            ")\n",
            "total_ice_season_length = total_ice_season_length.reset_index(name=\"ice_season_length\")\n",
            "\n",
            "total_first_catch.to_csv(\"../data/total_first_catch.csv\")\n",
            "total_last_catch.to_csv(\"../data/total_last_catch.csv\")\n",
            "total_ice_season_length.to_csv(\"../data/total_ice_season_length.csv\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### First and Last Days, by Locality, 2012-2022\n",
            "\n",
            "This dataframe brings together the first and last catch dates for each locality for each year, and which field codes were used on those dates, into one list. This list allows one to identify where the first and last fishing activity has taken place in each locality in each season."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [],
         "source": [
            "first_days = (\n",
            "    local_daily_catch.groupby(by=[\"seasonal_year\", \"sellers_locality\"])\n",
            "    .seasonal_day.min()\n",
            "    .reset_index()\n",
            "    .merge(\n",
            "        local_daily_catch[\n",
            "            [\n",
            "                \"seasonal_year\",\n",
            "                \"sellers_locality\",\n",
            "                \"field_code\",\n",
            "                \"seasonal_day\",\n",
            "                \"landing_date\",\n",
            "                \"amount_in_kg\",\n",
            "            ]\n",
            "        ]\n",
            "    )\n",
            "    .rename(columns={\"seasonal_day\": \"catch_day\", \"seasonal_year\": \"season\"})\n",
            ")\n",
            "\n",
            "first_days[\"first_or_last\"] = \"first\"\n",
            "\n",
            "last_days = (\n",
            "    local_daily_catch.groupby(by=[\"seasonal_year\", \"sellers_locality\"])\n",
            "    .seasonal_day.max()\n",
            "    .reset_index()\n",
            "    .merge(\n",
            "        local_daily_catch[\n",
            "            [\n",
            "                \"seasonal_year\",\n",
            "                \"sellers_locality\",\n",
            "                \"field_code\",\n",
            "                \"seasonal_day\",\n",
            "                \"landing_date\",\n",
            "                \"amount_in_kg\",\n",
            "            ]\n",
            "        ]\n",
            "    )\n",
            "    .rename(columns={\"seasonal_day\": \"catch_day\", \"seasonal_year\": \"season\"})\n",
            ")\n",
            "\n",
            "last_days[\"first_or_last\"] = \"last\"\n",
            "\n",
            "locality_seasons = pd.concat([first_days, last_days]).sort_values(\n",
            "    [\"season\", \"sellers_locality\"]\n",
            ")\n",
            "\n",
            "field_code_info = pd.read_csv(\"../data/fieldcodes.csv\")\n",
            "\n",
            "locality_seasons = locality_seasons.merge(\n",
            "    field_code_info, left_on=\"field_code\", right_on=\"fieldcode\"\n",
            ").drop(columns=\"fieldcode\")\n",
            "\n",
            "locality_seasons = locality_seasons[\n",
            "    [\n",
            "        \"season\",\n",
            "        \"sellers_locality\",\n",
            "        \"landing_date\",\n",
            "        \"first_or_last\",\n",
            "        \"catch_day\",\n",
            "        \"amount_in_kg\",\n",
            "        \"field_code\",\n",
            "        \"lat\",\n",
            "        \"lon\",\n",
            "    ]\n",
            "].sort_values([\"season\", \"sellers_locality\"])\n",
            "\n",
            "locality_seasons.to_csv(\"../data/locality_seasons.csv\", index=None)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Local First and Last Catch Days, 2012-2022\n",
            "\n",
            "#todo what is the difference between this and the code cell above?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [],
         "source": [
            "local_first_catch_dates = (\n",
            "    local_daily_catch.groupby(by=[\"seasonal_year\", \"field_code\", \"sellers_locality\"])\n",
            "    .seasonal_day.min()\n",
            "    .reset_index()\n",
            "    .rename(columns={\"seasonal_day\": \"first_catch_day\", \"seasonal_year\": \"season\"})\n",
            ")\n",
            "\n",
            "local_first_catch_dates.to_csv(\"../data/local_first_catch_dates.csv\")\n",
            "\n",
            "local_last_catch_dates = (\n",
            "    local_daily_catch.groupby(by=[\"seasonal_year\", \"field_code\", \"sellers_locality\"])\n",
            "    .seasonal_day.max()\n",
            "    .reset_index()\n",
            "    .rename(columns={\"seasonal_day\": \"last_catch_day\", \"seasonal_year\": \"season\"})\n",
            ")\n",
            "\n",
            "local_last_catch_dates.to_csv(\"../data/local_last_catch_dates.csv\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Local Ice Season Length\n",
            "\n",
            "#local versus total language is very confusing"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [],
         "source": [
            "local_ice_season_length = (\n",
            "    local_last_catch.set_index([\"season\", \"field_code\"]).last_catch_day\n",
            "    - local_first_catch.set_index([\"season\", \"field_code\"]).first_catch_day\n",
            ").reset_index(name=\"ice_season_length\")\n",
            "\n",
            "local_ice_season_length\n",
            "\n",
            "local_ice_season_length.to_csv(\"../data/local_ice_season_length.csv\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [],
         "source": [
            "# todo\n",
            "# derived\n",
            "# Only consider fields that appear in every season\n",
            "# fields_of_interest = set.intersection(*local_ice_season_length.groupby(by=['season']).field_code.unique().apply(lambda x: set(x)).values)\n",
            "\n",
            "\n",
            "# local_ice_season_length[local_ice_season_length.field_code.isin(fields_of_interest)].groupby('field_code').corr(method='kendall').unstack()['season']['ice_season_length']"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Number of Fields Fished, 2012-2022\n",
            "This calculates the number of field codes that were fished each season."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 30,
         "metadata": {},
         "outputs": [],
         "source": [
            "num_fields = (\n",
            "    local_first_catch.groupby(\"season\")\n",
            "    .field_code.nunique()\n",
            "    .rename(\"n_fields\")\n",
            "    .reset_index()\n",
            ")\n",
            "\n",
            "num_fields.to_csv(\"../data/num_fields.csv\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Local Number of Fields Fished, 2012-2022\n",
            "\n",
            "This calculates the number of field codes that were fished each season in each locality."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [],
         "source": [
            "local_num_fields = (\n",
            "    ice_landings.groupby(by=[\"seasonal_year\", \"sellers_locality\"])\n",
            "    .field_code.nunique()\n",
            "    .reset_index()\n",
            "    .rename(columns={\"field_code\": \"n_fields\"})\n",
            ")\n",
            "local_num_fields\n",
            "\n",
            "local_num_fields.to_csv(\"../data/local_num_fields.csv\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Fishing Grounds, by Locality, by Vessel Type, by Field Code, by Seasonal Year\n",
            "\n",
            "This identifies all of the fieldcodes that were fished in a season, from fishers in each locality, using either a water or ice vessel."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "metadata": {},
         "outputs": [],
         "source": [
            "field_code_info\n",
            "\n",
            "field_code_info.to_csv(\"../data/field_code_info.csv\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [
            {
               "ename": "KeyError",
               "evalue": "'KT020'",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                  "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3790\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3791\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
                  "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
                  "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
                  "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
                  "\u001b[0;31mKeyError\u001b[0m: 'KT020'",
                  "\nThe above exception was the direct cause of the following exception:\n",
                  "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                  "\u001b[0;32m/var/folders/4f/0mrpq3dn0tdg8ssxbsgsvt0m0000gn/T/ipykernel_48354/1312547602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m fishing_grounds[\"lon\"] = fishing_grounds.field_code.map(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfield_code_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n",
                  "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4538\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4539\u001b[0m         \"\"\"\n\u001b[0;32m-> 4540\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4541\u001b[0m         return self._constructor(new_values, index=self.index, copy=False).__finalize__(\n\u001b[1;32m   4542\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m         return lib.map_infer_mask(\n",
                  "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
                  "\u001b[0;32m/var/folders/4f/0mrpq3dn0tdg8ssxbsgsvt0m0000gn/T/ipykernel_48354/1312547602.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m fishing_grounds[\"lon\"] = fishing_grounds.field_code.map(\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfield_code_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
                  "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3795\u001b[0m             ):\n\u001b[1;32m   3796\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3797\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3798\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mKeyError\u001b[0m: 'KT020'"
               ]
            }
         ],
         "source": [
            "fishing_grounds = (\n",
            "    landings.groupby(\n",
            "        by=[\"seasonal_year\", \"sellers_locality\", \"vessel_type\", \"field_code\"]\n",
            "    )\n",
            "    .seller_id.nunique()\n",
            "    .reset_index()\n",
            "    .drop(columns=\"seller_id\")\n",
            ")\n",
            "\n",
            "\n",
            "fishing_grounds[\"lon\"] = fishing_grounds.field_code.map(\n",
            "    lambda x: field_code_info[x][\"lon\"]\n",
            ")\n",
            "fishing_grounds[\"lat\"] = fishing_grounds.field_code.map(\n",
            "    lambda x: field_code_info[x][\"lat\"]\n",
            ")\n",
            "\n",
            "fishing_grounds.to_csv(\"../data/fishing_grounds.csv\")"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.13"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}