{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook prepares landings records from the Government of Greenland, Fisheries Department, Fisheries License Control Authority, for the purposes of reproducing the results of the sea ice fishing study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huntersnyder/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Clean Landings Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings = pd.read_csv('../data/landings_raw.csv', index_col=0, encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary of Vessel Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels = {\n",
    "    'UJOLLE': None,\n",
    "    'USLAEDE': None,\n",
    "    'Dinghy': 'water',\n",
    "    'Larger Inshore Vessel': 'water',\n",
    "    'Sled': 'ice',\n",
    "    'Snowmobile': 'ice',\n",
    "    'ATV': None,\n",
    "}\n",
    "landings['vessel'] = landings.vessel_type\n",
    "landings['vessel_type'] = landings.vessel.map(vessels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Erroneous Localities Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1662470 entries in the landings dataset.\n"
     ]
    }
   ],
   "source": [
    "# Some localities have the wrong name\n",
    "landings['sellers_locality'] = landings['sellers_locality'].replace({'Tasiusaq, Upernavik': 'Upernavik'})\n",
    "landings['sellers_locality'] = landings['sellers_locality'].replace({'Kuummiit': 'Kuummiut'})\n",
    "landings['sellers_locality'] = landings['sellers_locality'].replace({'Tiileqilaaq': 'Tiniteqilaaq'})\n",
    "\n",
    "# Merge localities \n",
    "landings.loc[landings['sellers_locality'] == 'Aappilattoq Nanortalimmi', 'sellers_locality'] = 'Nanortalik'\n",
    "landings.loc[landings['sellers_locality'] == 'Aappilattoq Upernavimmi', 'sellers_locality'] = 'Upernavik'\n",
    "landings.loc[landings['sellers_locality'] == 'Nuussuaq, Nuuk', 'sellers_locality'] = 'Nuuk'\n",
    "landings.loc[landings['sellers_locality'] == 'Nuussuaq, Upernavik', 'sellers_locality'] = 'Upernavik'\n",
    "landings.loc[landings['sellers_locality'] == 'Tasiusaq Nanortalimmi', 'sellers_locality'] = 'Nanortalik'\n",
    "landings.loc[landings['sellers_locality'] == 'Tasiusaq, Upernavik', 'sellers_locality'] = 'Tasiusaq'\n",
    "landings.loc[landings['sellers_locality'] == 'Kuummiit', 'sellers_locality'] = 'Kuummiut'\n",
    "landings.loc[landings['buyers_locality'] == 'Aappilattoq Nanortalimmi', 'buyers_locality'] = 'Nanortalik'\n",
    "landings.loc[landings['buyers_locality'] == 'Aappilattoq Upernavimmi', 'buyers_locality'] = 'Upernavik'\n",
    "landings.loc[landings['buyers_locality'] == 'Nuussuaq, Nuuk', 'buyers_locality'] = 'Nuuk'\n",
    "landings.loc[landings['buyers_locality'] == 'Nuussuaq, Upernavik', 'buyers_locality'] = 'Upernavik'\n",
    "landings.loc[landings['buyers_locality'] == 'Tasiusaq Nanortalimmi', 'buyers_locality'] = 'Nanortalik'\n",
    "landings.loc[landings['buyers_locality'] == 'Tasiusaq, Upernavik', 'buyers_locality'] = 'Tasiusaq'\n",
    "landings.loc[landings['buyers_locality'] == 'Kuummiit', 'buyers_locality'] = 'Kuummiut'\n",
    "\n",
    "print(f'There are {landings.shape[0]} entries in the landings dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Erroneous Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings.dropna(subset= \"landing_date\", inplace =True)\n",
    "landings = landings.dropna(subset='num_tools')\n",
    "landings = landings[landings[\"num_tools\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1630798, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings = landings[~((landings[\"gear_en\"] == \"Longlines\") & (landings[\"num_tools\"] < 30))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings = landings[landings[\"fishing_time\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Spatial Data Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up degree symbols\n",
    "landings.latitude = landings.latitude.str.replace('¡', '°')\n",
    "landings.longitude = landings.longitude.str.replace('¡', '°')\n",
    "\n",
    "# Some missing data are okay, but some are an immediate disqualifier for further analysis of that row\n",
    "landings.dropna(subset=['seller_id'], inplace=True)\n",
    "\n",
    "field_codes = pd.read_csv('../data/fieldcodes.csv', index_col='fieldcode')\n",
    "field_codes = field_codes.to_dict(orient='index')\n",
    "\n",
    "def lookup_lat_lon(row):\n",
    "    \"\"\" Find latitude and longitude based on field code \"\"\"\n",
    "    try: \n",
    "        row['latitude'] = field_codes[row['field_code']]['lat']\n",
    "        row['longitude'] = field_codes[row['field_code']]['lon']\n",
    "    except KeyError:\n",
    "        row['latitude'] = None\n",
    "        row['longitude'] = None\n",
    "    return row\n",
    "\n",
    "landings = landings.apply(lookup_lat_lon, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fieldcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_code_info = pd.read_csv('../data/fieldcodes.csv', index_col='fieldcode').to_dict(orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings['field_code'] = landings.field_code.str.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_zero_padding(field_code):\n",
    "    try:\n",
    "        return field_code[:2] + f'{int(field_code[2:]):03d}'                \n",
    "    except (ValueError, TypeError):\n",
    "        return field_code\n",
    "    \n",
    "landings['field_code'] = landings.field_code.apply(insert_zero_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 'I/O',\n",
       " 'JO027',\n",
       " 'BL021',\n",
       " 'LMD017',\n",
       " 'MI029',\n",
       " 'MI019',\n",
       " 'AG024',\n",
       " 'LN287',\n",
       " 'I/(O',\n",
       " 'JO025',\n",
       " 'I/000',\n",
       " 'LC025',\n",
       " 'LO020',\n",
       " 'LD021LD021',\n",
       " 'J0028',\n",
       " 'A6048',\n",
       " 'GK057',\n",
       " 'UJ021',\n",
       " 'ZF019',\n",
       " 'LE',\n",
       " 'CP020',\n",
       " 'LHJ02',\n",
       " 'LLJ02',\n",
       " 'A6047',\n",
       " 'LGG02',\n",
       " 'KS',\n",
       " 'LG',\n",
       " 'AA016']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_field_codes = []\n",
    "for field_code in landings.field_code.unique():\n",
    "    if not field_code in field_code_info.keys():\n",
    "        bad_field_codes.append(field_code)\n",
    "\n",
    "bad_field_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings = landings[~landings.field_code.isin(bad_field_codes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Derived Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Seasonal Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings['landing_date'] =  pd.to_datetime(landings.landing_date)\n",
    "landings['seasonal_year'] = landings.landing_date.apply(lambda x: x.year - 1 if x.month < 8 else x.year)\n",
    "landings = landings.query(\"seasonal_year > 2011 & seasonal_year < 2023\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Catch Per Unit of Effort (CPUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520208, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_cpue(landing):\n",
    "    if landing.gear_en == \"Longlines\":\n",
    "        landing.cpue = landing.amount_in_kg / (landing.num_tools / 100) / landing.fishing_time\n",
    "    elif landing.gear_en == \"Gill nets\":\n",
    "        landing.cpue = landing.amount_in_kg / landing.num_tools / landing.fishing_time\n",
    "    return landing\n",
    "landings[\"cpue\"] = None\n",
    "\n",
    "landings = landings.apply(calculate_cpue, axis=1)\n",
    "landings.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Price Per Kilo (DKK/kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings['ppk'] = landings.value / landings.amount_in_kg\n",
    "landings.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "landings.dropna(subset=['cpue', 'ppk'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Derived Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Price Per Kilo According to Locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppk_locality = landings.groupby(by=['sellers_locality', 'seasonal_year']).ppk.mean().reset_index()\n",
    "\n",
    "ppk_locality\n",
    "\n",
    "ppk_locality.to_csv('ppk_locality.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
